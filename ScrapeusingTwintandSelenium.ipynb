{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91046bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f6255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a77dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from time import sleep\n",
    "from msedge.selenium_tools import Edge, EdgeOptions\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common import exceptions\n",
    "\n",
    "\n",
    "def create_webdriver_instance():\n",
    "    options = EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    driver = Edge(options=options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def login_to_twitter(username, password, driver):\n",
    "    url = 'https://twitter.com/login'\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        xpath_username = '//input[@name=\"session[username_or_email]\"]'\n",
    "        WebDriverWait(driver, 10).until(expected_conditions.presence_of_element_located((By.XPATH, xpath_username)))\n",
    "        uid_input = driver.find_element_by_xpath(xpath_username)\n",
    "        uid_input.send_keys(username)\n",
    "    except exceptions.TimeoutException:\n",
    "        print(\"Timeout while waiting for Login screen\")\n",
    "        return False\n",
    "\n",
    "    pwd_input = driver.find_element_by_xpath('//input[@name=\"session[password]\"]')\n",
    "    pwd_input.send_keys(password)\n",
    "    try:\n",
    "        pwd_input.send_keys(Keys.RETURN)\n",
    "        url = \"https://twitter.com/home\"\n",
    "        WebDriverWait(driver, 10).until(expected_conditions.url_to_be(url))\n",
    "    except exceptions.TimeoutException:\n",
    "        print(\"Timeout while waiting for home screen\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def find_search_input_and_enter_criteria(search_term, driver):\n",
    "    xpath_search = '//input[@aria-label=\"Search query\"]'\n",
    "    search_input = driver.find_element_by_xpath(xpath_search)\n",
    "    search_input.send_keys(search_term)\n",
    "    search_input.send_keys(Keys.RETURN)\n",
    "    return True\n",
    "\n",
    "\n",
    "def change_page_sort(tab_name, driver):\n",
    "    \"\"\"Options for this program are `Latest` and `Top`\"\"\"\n",
    "    tab = driver.find_element_by_link_text(tab_name)\n",
    "    tab.click()\n",
    "    xpath_tab_state = f'//a[contains(text(),\\\"{tab_name}\\\") and @aria-selected=\\\"true\\\"]'\n",
    "\n",
    "\n",
    "def generate_tweet_id(tweet):\n",
    "    return ''.join(tweet)\n",
    "\n",
    "\n",
    "def scroll_down_page(driver, last_position, num_seconds_to_load=0.5, scroll_attempt=0, max_attempts=5):\n",
    "    \"\"\"The function will try to scroll down the page and will check the current\n",
    "    and last positions as an indicator. If the current and last positions are the same after `max_attempts`\n",
    "    the assumption is that the end of the scroll region has been reached and the `end_of_scroll_region`\n",
    "    flag will be returned as `True`\"\"\"\n",
    "    end_of_scroll_region = False\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    sleep(num_seconds_to_load)\n",
    "    curr_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "    if curr_position == last_position:\n",
    "        if scroll_attempt < max_attempts:\n",
    "            end_of_scroll_region = True\n",
    "        else:\n",
    "            scroll_down_page(last_position, curr_position, scroll_attempt + 1)\n",
    "    last_position = curr_position\n",
    "    return last_position, end_of_scroll_region\n",
    "\n",
    "\n",
    "def save_tweet_data_to_csv(records, filepath, mode='a+'):\n",
    "    header = ['User', 'Handle', 'PostDate', 'TweetText', 'ReplyCount', 'RetweetCount', 'LikeCount']\n",
    "    with open(filepath, mode=mode, newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if mode == 'w':\n",
    "            writer.writerow(header)\n",
    "        if records:\n",
    "            writer.writerow(records)\n",
    "\n",
    "\n",
    "def collect_all_tweets_from_current_view(driver, lookback_limit=25):\n",
    "    \"\"\"The page is continously loaded, so as you scroll down the number of tweets returned by this function will\n",
    "     continue to grow. To limit the risk of 're-processing' the same tweet over and over again, you can set the\n",
    "     `lookback_limit` to only process the last `x` number of tweets extracted from the page in each iteration.\n",
    "     You may need to play around with this number to get something that works for you. I've set the default\n",
    "     based on my computer settings and internet speed, etc...\"\"\"\n",
    "    page_cards = driver.find_elements_by_xpath('//div[@data-testid=\"tweet\"]')\n",
    "    if len(page_cards) <= lookback_limit:\n",
    "        return page_cards\n",
    "    else:\n",
    "        return page_cards[-lookback_limit:]\n",
    "\n",
    "\n",
    "def extract_data_from_current_tweet_card(card):\n",
    "    try:\n",
    "        user = card.find_element_by_xpath('.//span').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        user = \"\"\n",
    "    except exceptions.StaleElementReferenceException:\n",
    "        return\n",
    "    try:\n",
    "        handle = card.find_element_by_xpath('.//span[contains(text(), \"@\")]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        handle = \"\"\n",
    "    try:\n",
    "        \"\"\"\n",
    "        If there is no post date here, there it is usually sponsored content, or some\n",
    "        other form of content where post dates do not apply. You can set a default value\n",
    "        for the postdate on Exception if you which to keep this record. By default I am\n",
    "        excluding these.\n",
    "        \"\"\"\n",
    "        postdate = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "    except exceptions.NoSuchElementException:\n",
    "        return\n",
    "    try:\n",
    "        _comment = card.find_element_by_xpath('.//div[2]/div[2]/div[1]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        _comment = \"\"\n",
    "    try:\n",
    "        _responding = card.find_element_by_xpath('.//div[2]/div[2]/div[2]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        _responding = \"\"\n",
    "    tweet_text = _comment + _responding\n",
    "    try:\n",
    "        reply_count = card.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        reply_count = \"\"\n",
    "    try:\n",
    "        retweet_count = card.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        retweet_count = \"\"\n",
    "    try:\n",
    "        like_count = card.find_element_by_xpath('.//div[@data-testid=\"like\"]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        like_count = \"\"\n",
    "\n",
    "    tweet = (user, handle, postdate, tweet_text, reply_count, retweet_count, like_count)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def main(username, password, search_term, filepath, page_sort='Latest'):\n",
    "    save_tweet_data_to_csv(None, filepath, 'w')  # create file for saving records\n",
    "    last_position = None\n",
    "    end_of_scroll_region = False\n",
    "    unique_tweets = set()\n",
    "\n",
    "    driver = create_webdriver_instance()\n",
    "    logged_in = login_to_twitter(username, password, driver)\n",
    "    if not logged_in:\n",
    "        return\n",
    "\n",
    "    search_found = find_search_input_and_enter_criteria(search_term, driver)\n",
    "    if not search_found:\n",
    "        return\n",
    "\n",
    "    change_page_sort(page_sort, driver)\n",
    "\n",
    "    while not end_of_scroll_region:\n",
    "        cards = collect_all_tweets_from_current_view(driver)\n",
    "        for card in cards:\n",
    "            try:\n",
    "                tweet = extract_data_from_current_tweet_card(card)\n",
    "            except exceptions.StaleElementReferenceException:\n",
    "                continue\n",
    "            if not tweet:\n",
    "                continue\n",
    "            tweet_id = generate_tweet_id(tweet)\n",
    "            if tweet_id not in unique_tweets:\n",
    "                unique_tweets.add(tweet_id)\n",
    "                save_tweet_data_to_csv(tweet, filepath)\n",
    "        last_position, end_of_scroll_region = scroll_down_page(driver, last_position)\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    usr = \"email@gmail.com\"\n",
    "    pwd = \"password\"\n",
    "    path = 'pysimplegui.csv'\n",
    "    term = 'pysimplegui'\n",
    "\n",
    "    main(usr, pwd, term, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ebd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#webscrap using twint\n",
    "import twint\n",
    "import os\n",
    "\n",
    "'''\n",
    "Test.py - Testing TWINT to make sure everything works.\n",
    "'''\n",
    "\n",
    "\n",
    "def test_reg(c, run):\n",
    "    print(\"[+] Beginning vanilla test in {}\".format(str(run)))\n",
    "    run(c)\n",
    "\n",
    "\n",
    "def test_db(c, run):\n",
    "    print(\"[+] Beginning DB test in {}\".format(str(run)))\n",
    "    c.Database = \"test_twint.db\"\n",
    "    run(c)\n",
    "\n",
    "\n",
    "def custom(c, run, _type):\n",
    "    print(\"[+] Beginning custom {} test in {}\".format(_type, str(run)))\n",
    "    c.Custom['tweet'] = [\"id\", \"username\"]\n",
    "    c.Custom['user'] = [\"id\", \"username\"]\n",
    "    run(c)\n",
    "\n",
    "\n",
    "def test_json(c, run):\n",
    "    c.Store_json = True\n",
    "    c.Output = \"test_twint.json\"\n",
    "    custom(c, run, \"JSON\")\n",
    "    print(\"[+] Beginning JSON test in {}\".format(str(run)))\n",
    "    run(c)\n",
    "\n",
    "\n",
    "def test_csv(c, run):\n",
    "    c.Store_csv = True\n",
    "    c.Output = \"test_twint.csv\"\n",
    "    custom(c, run, \"CSV\")\n",
    "    print(\"[+] Beginning CSV test in {}\".format(str(run)))\n",
    "    run(c)\n",
    "\n",
    "\n",
    "def main():\n",
    "    c = twint.Config()\n",
    "    c.Username = \"verified\"\n",
    "    c.Limit = 20\n",
    "    c.Store_object = True\n",
    "\n",
    "    # Separate objects are necessary.\n",
    "\n",
    "    f = twint.Config()\n",
    "    f.Username = \"verified\"\n",
    "    f.Limit = 20\n",
    "    f.Store_object = True\n",
    "    f.User_full = True\n",
    "\n",
    "    runs = [\n",
    "        twint.run.Profile,  # this doesn't\n",
    "        twint.run.Search,  # this works\n",
    "        twint.run.Following,\n",
    "        twint.run.Followers,\n",
    "        twint.run.Favorites,\n",
    "    ]\n",
    "\n",
    "    tests = [test_reg, test_json, test_csv, test_db]\n",
    "\n",
    "    # Something breaks if we don't split these up\n",
    "\n",
    "    for run in runs[:3]:\n",
    "        if run == twint.run.Search:\n",
    "            c.Since = \"2012-1-1 20:30:22\"\n",
    "            c.Until = \"2017-1-1\"\n",
    "        else:\n",
    "            c.Since = \"\"\n",
    "            c.Until = \"\"\n",
    "\n",
    "        for test in tests:\n",
    "            test(c, run)\n",
    "\n",
    "    for run in runs[3:]:\n",
    "        for test in tests:\n",
    "            test(f, run)\n",
    "\n",
    "    files = [\"test_twint.db\", \"test_twint.json\", \"test_twint.csv\"]\n",
    "    for _file in files:\n",
    "        os.remove(_file)\n",
    "\n",
    "    print(\"[+] Testing complete!\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd16597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ebb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674887fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
